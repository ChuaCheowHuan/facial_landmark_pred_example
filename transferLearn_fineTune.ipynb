{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transferLearn_fineTune.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb","timestamp":1617611164005}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Lhb-bm1NhKJR"},"source":["#Mount google drive."]},{"cell_type":"code","metadata":{"id":"9fGfHbElzYXd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P0F4huZdgqLg"},"source":["#Imports."]},{"cell_type":"code","metadata":{"id":"iBMcobPHdD8O"},"source":["import tensorflow as tf\n","assert tf.__version__.startswith('2')\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","\n","#from PIL import Image\n","\n","import os\n","\n","import time\n","\n","# Change path in Colab.\n","!pwd\n","%cd \"/content/drive/My Drive/Colab Notebooks/facial_landmark_pred_example/\"\n","!ls -l\n","\n","from Helper.My_Display import My_Display\n","\n","tf.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0t_p4GL-hrRN"},"source":["#Setup paths."]},{"cell_type":"code","metadata":{"id":"LUqmrFMYhrhk"},"source":["path = \"/content/drive/My Drive/Colab Notebooks/facial_landmark_pred_example/\"\n","#path = r\"C:/Users/USER/Google Drive/Colab Notebooks/facial_landmark_pred_example\"\n","\n","data_path = path + 'tfrec_data/'\n","facenet_path = path + \"facenet/model/\"\n","checkpoint_path = path + 'chkpt/'\n","saved_model_path = path + \"saved_model/\"\n","saved_fig_dir = path + \"saved_fig/saved_fig.png\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uee9oY0-xD_"},"source":["#Sizes, dimensions & hyperparameters."]},{"cell_type":"code","metadata":{"id":"zBx08UPSPqB6"},"source":["test_size = 466     # Size of test set (20% of total dataset size).\n","IMAGE_SIZE = 160      # w, h of image.\n","IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)      # Shape of image with 3 channels.\n","top_dropout_rate = 0.2      # Dropout rate for dropout layer.\n","\n","# The output is a vector of size 388 float between 0 to 1.\n","num_output = 388      # 388 represents all x, y values of 194 coordinates.\n","\n","BATCH_SIZE = 4      # For training.\n","epochs = 15     # For transfer learning.\n","epochs_fine_tune = 150     # For fine tuning.\n","batches = 46     # For checkpoint.\n","\n","lr_fine_tune = 1e-5     # learning rate for fine tuning.\n","# Fine tune from this layer onwards\n","fine_tune_at = 0      # 0 means fine tune all layers."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NTYIvj7rhUOC"},"source":["#Read dataset."]},{"cell_type":"code","metadata":{"id":"OgSslxzchewc"},"source":["raw_dataset = tf.data.TFRecordDataset([data_path + 'tfrec_data_1', \n","                                       data_path + 'tfrec_data_2',\n","                                       data_path + 'tfrec_data_3', \n","                                       data_path + 'tfrec_data_4', \n","                                       data_path + 'tfrec_data_5', \n","                                       ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47Oe6tECnzfb"},"source":["# Display attributes of raw_dataset.\n","print(tf.data.experimental.cardinality(raw_dataset).numpy())\n","print(len(list(raw_dataset)))\n","\n","cardinality = tf.data.experimental.cardinality(raw_dataset)\n","print((cardinality == tf.data.experimental.INFINITE_CARDINALITY).numpy())\n","print((cardinality == tf.data.experimental.UNKNOWN_CARDINALITY).numpy())\n","\n","raw_example = next(iter(raw_dataset))\n","parsed = tf.train.Example.FromString(raw_example.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pdcgprcf_Dfw"},"source":["##Function to parse data."]},{"cell_type":"code","metadata":{"id":"WRTDBD9Rhfp_"},"source":["# Create a description of the features.\n","feature_description = {\n","    'img_name': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","    'img': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","    'coords': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2sdcPX_SHve"},"source":["def _parse_function(example_proto):\n","  # Parse the input `tf.train.Example` proto using the dictionary above.\n","  map_ds = tf.io.parse_single_example(example_proto, feature_description)    \n","  img_name = map_ds['img_name']\n","  img = tf.image.decode_jpeg(map_ds['img'])     \n","  coords = tf.io.decode_raw(map_ds['coords'], 'double')     # float64\n","  print(map_ds, img_name, img, coords)\n","\n","  # Get img original size.\n","  w = tf.shape(img)[1]\n","  h = tf.shape(img)[0]\n","\n","  # Resize img.\n","  img = tf.image.resize(img, [IMAGE_SIZE,IMAGE_SIZE])\n","\n","  # Normalize img, not neccessary.\n","  #img = tf.math.divide(img, 255)\n","\n","  # Get the scale factor.\n","  w_scale_factor = tf.math.divide(IMAGE_SIZE, w)\n","  h_scale_factor = tf.math.divide(IMAGE_SIZE, h)\n","  \n","  # Scale the coords.\n","  coords_dim = (194,2)\n","  coords = tf.reshape(coords, coords_dim)\n","  coord_vec_0 = tf.slice(coords, [0, 0], [194, 1])\n","  coord_vec_1 = tf.slice(coords, [0, 1], [194, 1])\n","  coord_vec_0_scaled = tf.math.multiply(coord_vec_0, w_scale_factor)\n","  coord_vec_1_scaled = tf.math.multiply(coord_vec_1, h_scale_factor)\n","\n","  # Normalize coords\n","  coord_vec_0_scaled = tf.math.divide(coord_vec_0_scaled, IMAGE_SIZE)\n","  coord_vec_1_scaled = tf.math.divide(coord_vec_1_scaled, IMAGE_SIZE)\n","  coords = tf.concat([coord_vec_0_scaled, coord_vec_1_scaled], 1)\n","  coords_dim = (388,1)\n","  coords = tf.reshape(coords, coords_dim)\n","\n","  return img, coords  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8hQh0zCCb9H"},"source":["##Train/test split."]},{"cell_type":"code","metadata":{"id":"uWqwPO11xLO5"},"source":["test_dataset = raw_dataset.take(test_size) \n","train_dataset = raw_dataset.skip(test_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6lAtffnklsEz"},"source":["##Parse train, test set."]},{"cell_type":"code","metadata":{"id":"MBhFsq0jcAkc"},"source":["parsed_dataset_train = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","parsed_dataset_test = test_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","print(parsed_dataset_train)\n","print(parsed_dataset_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lorZSfFFfo65"},"source":["parsed_dataset_train = parsed_dataset_train.cache()\n","parsed_dataset_train = parsed_dataset_train.shuffle(500, seed=1234, reshuffle_each_iteration=True)\n","parsed_dataset_train = parsed_dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n","parsed_dataset_train = parsed_dataset_train.prefetch( tf.data.experimental.AUTOTUNE)\n","parsed_dataset_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJp37gkmPk-w"},"source":["parsed_dataset_test = parsed_dataset_test.cache()\n","parsed_dataset_test = parsed_dataset_test.shuffle(500, seed=1234, reshuffle_each_iteration=True)\n","parsed_dataset_test = parsed_dataset_test.batch(BATCH_SIZE, drop_remainder=True)\n","parsed_dataset_test = parsed_dataset_test.prefetch( tf.data.experimental.AUTOTUNE)\n","parsed_dataset_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wdMRM8YModbk"},"source":["#Build model for transfer learning."]},{"cell_type":"code","metadata":{"id":"w2gBUZLoe0fd"},"source":["# Load the pretrained keras facenet model.\n","facenet_model = keras.models.load_model(facenet_path + 'facenet_keras.h5')\n","\n","base_model = facenet_model\n","base_model.trainable = False      # Fix the weights of the base facenet model.\n","\n","# Replace clasification head from facenet model with one that does regression.\n","x = base_model.layers[-2].output    # Remove the last output layer.\n","\n","# Add Dropout, BatchNorm & Dense layers. \n","x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)    \n","x = layers.BatchNormalization()(x)\n","outputs = layers.Dense(num_output, activation=\"sigmoid\", name=\"pred\")(x)\n","\n","# Setup model.\n","model = tf.keras.Model(facenet_model.input, \n","                      outputs,\n","                      name=\"facenet_model_mod\")\n","\n","optimizer = tf.keras.optimizers.Adam()      # Select optimizer.\n","# Compile model.\n","model.compile(optimizer=optimizer, \n","              loss=\"mse\", \n","              metrics=[\"mse\",],\n",")\n","\n","print('Number of trainable variables = {}'.format(len(model.trainable_variables)))\n","model.summary()\n","#tf.keras.utils.plot_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wjnj94mO-jim"},"source":["##Setup chkpt."]},{"cell_type":"code","metadata":{"id":"i_rPIIlu-jqP"},"source":["# Include the epoch in the file name (uses `str.format`)\n","\n","checkpoint_file = checkpoint_path + \"/cp-{epoch:04d}.ckpt\"\n","print(os.listdir(checkpoint_path))\n","\n","# Create a callback that saves the model's weights every 5 epochs\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_file, \n","    verbose=1, \n","    save_weights_only=True,\n","    save_freq=batches*BATCH_SIZE)\n","\n","# Save the weights using the `checkpoint_path` format\n","#model.save_weights(checkpoint_file.format(epoch=0))\n","\n","#file = '/content/drive/My Drive/Colab Notebooks/models/digit_mnist_apml.h5'\n","#Check whether a saved model existed, if true we load it\n","if os.listdir(checkpoint_path):\n","    # Loads the weights\n","    #model.load_weights(checkpoint_path)\n","    #model.load_weights(checkpoint_path.format(epoch=0))\n","    latest = tf.train.latest_checkpoint(checkpoint_path)\n","    print(latest)\n","    #model.load_weights(latest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RxvgOYTDSWTx"},"source":["## Train the model (transfer learning)"]},{"cell_type":"code","metadata":{"id":"2zdjJJZqgrGB"},"source":["import time\n","start_time = time.time()\n","\n","history = model.fit(parsed_dataset_train, \n","                    epochs=epochs, \n","                    validation_data=parsed_dataset_test, \n","                    callbacks=[cp_callback],\n","                    verbose=1,\n","                    )\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hd94CKImf8vi"},"source":["### Learning curves\n"]},{"cell_type":"code","metadata":{"id":"53OTCh3jnbwV"},"source":["loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(loss, label='Training loss')\n","plt.plot(val_loss, label='Validation loss')\n","plt.legend(loc='best')\n","plt.ylabel('loss')\n","plt.title('Training and Validation lossloss')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J_oluIUSzG6B"},"source":["###Test transfer learning results."]},{"cell_type":"code","metadata":{"id":"s0gBBt-lzHES"},"source":["n = 3      # 3 batches.\n","samples = parsed_dataset_test.take(n)     \n","pred = model.predict(samples)\n","results = model.evaluate(samples)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CqwV-CRdS6Nv"},"source":["## Fine tuning"]},{"cell_type":"code","metadata":{"id":"-4HgVAacRs5v"},"source":["base_model.trainable = True\n","\n","# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False\n","\n","print('Number of trainable variables = {}'.format(len(base_model.trainable_variables)))  \n","#base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Uk1dgsxT0IS"},"source":["###Compile the model using a much lower training rate."]},{"cell_type":"code","metadata":{"id":"NtUnaz0WUDva"},"source":["model.compile(optimizer=tf.keras.optimizers.Adam(lr_fine_tune),             \n","              loss='mse',\n","              metrics=[tf.keras.metrics.MeanSquaredError(),],\n","              )\n","\n","print('Number of trainable variables = {}'.format(len(model.trainable_variables)))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4G5O4jd6TuAG"},"source":["### Continue to train the model."]},{"cell_type":"code","metadata":{"id":"ECQLkAsFTlun"},"source":["import time\n","start_time = time.time()\n","\n","history_fine = model.fit(parsed_dataset_train,                         \n","                         epochs=epochs_fine_tune, \n","                         validation_data=parsed_dataset_test, \n","                         callbacks=[cp_callback],\n","                         verbose=1,\n","                         )\n","print(\"--- %s seconds ---\" % (time.time() - start_time))                        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXsMwHdIXdc7"},"source":["loss = history_fine.history['loss']\n","val_loss = history_fine.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(loss, label='Training loss')\n","plt.plot(val_loss, label='Validation loss')\n","plt.legend(loc='best')\n","plt.ylabel('loss')\n","plt.title('Training and Validation lossloss')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_t94UtukBze"},"source":["###Test fine tuning result."]},{"cell_type":"code","metadata":{"id":"1Pl1rCgd5RXE"},"source":["n = 3      # 3 batches.\n","samples = parsed_dataset_test.take(n)     \n","pred = model.predict(samples)\n","results = model.evaluate(samples)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYcmA80JiaeR"},"source":["#Save model."]},{"cell_type":"code","metadata":{"id":"_LZiKVInWNGy"},"source":["#assert False      # Stop cells from running.\n","\n","#tf.saved_model.save(model, saved_model_path)     # tf\n","model.save(saved_model_path + 'saved_model.h5')      # tf.keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kRDabW_u1wnv"},"source":["## Convert & save as TFLite model."]},{"cell_type":"code","metadata":{"id":"cWPm_K5gurOO"},"source":["converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n","tflite_model = converter.convert()\n","\n","with open(saved_model_path + 'saved_model.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GE4w-9S410Dk"},"source":["###Download the converted model and labels"]},{"cell_type":"code","metadata":{"id":"x47uW_lI1DoV"},"source":["#from google.colab import files\n","\n","#files.download('model.tflite')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WoM7jPJpeSrs"},"source":["#Load saved model, test & display results."]},{"cell_type":"code","metadata":{"id":"6LBtvL5uaLxY"},"source":["# Load saved trained model.\n","saved_model = tf.keras.models.load_model(saved_model_path + 'saved_model.h5')     \n","saved_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jxg6UJqyaOnP"},"source":["# 1 batch = 4 samples, 75 batches = 300 samples.\n","samples = parsed_dataset_test.take(75)      \n","#pred = saved_model.predict(samples)\n","results = saved_model.evaluate(samples)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoI-pWevdMRM"},"source":["# Display fine tune results.\n","fig=plt.figure(figsize=(20, 150))\n","rows = 60\n","cols = 10\n","show = My_Display()\n","show.display_test_fine_tune(samples, saved_model, IMAGE_SIZE, \n","                            fig, rows, cols, \n","                            saved_fig_dir)"],"execution_count":null,"outputs":[]}]}